# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
gremlin.graph=org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph
gremlin.hadoop.graphInputFormat=org.apache.tinkerpop.gremlin.hadoop.structure.io.script.ScriptInputFormat
gremlin.hadoop.graphOutputFormat=org.apache.tinkerpop.gremlin.hadoop.structure.io.graphson.GraphSONOutputFormat
gremlin.hadoop.jarsInDistributedCache=true

gremlin.hadoop.inputLocation=/datasets/sf10_updates/adjacency_format/part-00000
gremlin.hadoop.scriptInputFormat.script=/scripts/script-input-ldbc-snb.groovy
gremlin.hadoop.outputLocation=output

gremlin.bulkLoaderVertexProgram.intermediateBatchSize = 10000

####################################
# SparkGraphComputer Configuration #
####################################
spark.master=spark://192.168.152.200:7077
# spark.master=local[8]
spark.cores.max=50
spark.executor.memory=16g
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.executor.cores=5
spark.driver.extraClassPath=/home/apacaci/ldbc-gremlin/janusgraph/lib/groovy-2.4.7.jar
spark.executor.extraClassPath=/home/apacaci/ldbc-gremlin/janusgraph/lib/groovy-2.4.7.jar
spark.jar.excludes=org.codehaus.groovy:groovy-all:jar:2.1.6
spark.driver.maxResultSize=8g
gremlin.spark.graphStorageLevel=MEMORY_AND_DISK
gremlin.spark.persistStorageLevel=MEMORY_AND_DISK
gremlin.spark.persistContext=true
# spark.kryo.registrationRequired=true
# spark.storage.memoryFraction=0.2
# spark.eventLog.enabled=true
# spark.eventLog.dir=/tmp/spark-event-logs
# spark.ui.killEnabled=true

